{"posts":[{"title":"从win10开始配置ubuntu18.04双系统+pytorch-gpu深度学习环境","content":"Author: 王子腾 本文整理了从win10开始配置ubuntu18.04双系统，以及Anaconda+Pytorch-gpu环境。本着不重复造轮子的原则，仅引用梳理优秀的现有教程 总体步骤 安装双系统 更改显卡驱动 安装anaconda 安装pytorch 安装vscode 安装双系统 本文作于2020.09，ubuntu最新版本为20.04，但是由于很多应用没有适配，更加推荐18.04版本。 推荐教程： ubuntu18,04双系统安装教程 需要注意的是，制作系统盘和安装过程，大同小异，但是U盘启动的步骤，不同品牌不同型号的电脑都有差异，请自行百度。 安装独立显卡驱动 和 cuda 一般pytorch需要独立显卡加速，当然如果只安装cpu版本，就不用了。 选择18.04版本的原因，其中之一就是平台本身提供稳定的先打驱动，安装简单，具体安装步骤，请参考该知乎回答的第一种即可： ubuntu18.04安装nvidia独立显卡驱动 GPU加速还需要nvidia的cuda支持，可以直接从官网安装。目前推荐10.2版本，链接如下，安装直接跟着页面上的教程即可 cuda10.2下载安装 安装之后，在terminal中输入nvidia-smi 可以查看当前的显卡使用信息 安装anaconda和pytorch anaconda是一个用来管理python环境和包的软件，可以创建彼此独立的虚拟环境，推荐安装。 安装根据下面的教程即可。推荐使用清华源，国内没有梯子的话直接下载速度可能会很慢。另外就是中间提示加入环境变量最好用yes 安装anaconda 安装完成之后，打开terminal应该在命令最前面出现(base)，说明安装成功。 然后推荐使用虚拟环境，命令为conda create -n &lt;env_name&gt; python=&lt;python version&gt;，例如conda create -n torch_env python=3.7，完成后conda activate &lt;env_name&gt; 激活环境。 具体conda的使用方法参见anaconda使用教程 激活环境后，即可按照pytorch官网中的命令安装pytorch. 相应链接为pytorch 安装，推荐使用pip安装，不出意外命令应该是pip install torch torchvision。 但是直接安装由于GFW的原因，很可能特别慢，可以更换使用清华源进行安装。 清华源官方使用方法 安装之后，在terminal中输入python，在交互环境中import torch ，不报错说明pytorch安装成功，再输入torch.cuda.is_available()，如果输出True说明可以使用gpu。 VSCODE 编辑器推荐使用vscode，只需要再官网中下载，然后安装python插件即可。激活python插件后，在左下角可以选择python interpretor，选择相应的虚拟环境，即可享受完整的代码补全等功能。 运行代码推荐直接使用terminal运行。 ","link":"https://tonywangziteng.github.io/post/cong-win10-kai-shi-pei-zhi-ubuntu1804-shuang-xi-tong-pytorch-gpu-shen-du-xue-xi-huan-jing/"},{"title":"PBRNet：Progressive Boundary Refinement Network for Temporal Action Detection","content":"Author Qinying Liu, Zilei Wang, 中科大 Department of Automation 主要特点 One-stage, Anchor-Based Three cascaded modules to progressively fine-tune results 利用UNet型网络，充分利用了frame-level的信息 PBRNet 具体结构以及tricks 整个网络结构分为三个部分： CPD: Coarse Pyramidal Detection RPD: Refined Pyramidal Detection FGD: Fine-grained Detection CPD 利用FPN网络来提取不同感受野的特征，并且利用这些特征来对 preset anchors 进行第一步的调整。 对于THUMOS14来讲，作者采用了五层，分别对应了（L/8, L/16, L/32, L/64, L/128）五个尺度的anchors。但是由于浅层网络缺少semantic的信息，而深层网络缺乏细节信息，因此这个过程中只能作为粗调使用。 FPN的每一层都保持3*3的spatil dim，长度L减半。由feature map 到anchors调整的classification 和 loacation regression 信息是通过3*3*3的3D卷积实现的 RPD 从这个地方开始，作者开始了一系列骚操作。 这一部分是CPD的对偶的结构，利用步长为2的上采样不断恢复长度。同时将CPD中相应长度的 feature map 直接拉过来，通过上图中的FBv1中的结构进行融合。保证RPD中的细节信息足够。同时基于对偶的结构，直接将CPD中的 coarse proposals 拉到这里作为进一步调整的对象。 这种UNet样式的结构在2019年的一篇文章中用过，作者生成他们利用这两个网络级联来 Progressive 的进行classification and location regression，是他们的创新点。 FGD 这里应该算是作者自己提出的最后进行 frame level fine tune 的网络。这里作者又进行了一波操作 通过上图中的FBv2模块，把RPD网络的最后一层输出和原视频序列直接融合在一起，形成了一个frame-level 的 feature map。 在这个frame-level的feature map上，过3*3*3的3D卷积得到了actioness, start, end的三个打分结果。此处的每一个结果都是按照类别进行得，也就是有一个k维的维度，k是动作类别。根据文章中，这三个branch的作用是增加semantic信息，以及参与最后anchor的打分挑选。个人认为semantic信息那一条属实牵强。 然后对于提出的proposal，首先分别定位到frame-level的feacure-map中，然后在开始和结束的位置分别取出t/β\\betaβ的长度(t是proposal的时间，β\\betaβ在THUMOS14中是8)，进行时间维度空洞的三位卷积，进行最终的fine-tune。 Details and tricks 到这里整个网络的大体结构就说完了，剩下是一些细节上的操作和处理的方法。 预处理：Progressive Matching Strategy 在定义positive and negative sample的时候，最主要是通过IOU，当IOU超过一定threshold之后认为是正例。所有的positive sample中，认为得分最高的就是ground truth。这里使用了一个trick是对于CPD, FPD, FGD三个module，threshold分别是0.5, 0.6, 0.7，以此来保证他所谓的Progressive。 处理正负样本不均衡 在前期的过程中会直接预测anchor是bachgroud的得分，只保留得分低的anchor。对于背景类，用难例挖掘。保留负样本中loss比较高的，应该是可以提供更多的信息。 类别得分 pk=pcpk⋅prpk⋅psk⋅pekp^k=p^k_{cp}\\cdot p^k_{rp}\\cdot p^k_s\\cdot p^k_e pk=pcpk​⋅prpk​⋅psk​⋅pek​ 作者声称这样可以结合anchor的类别信息和start, end的类别信息，更加准确 conclusion Unet的结构可以参考， 主要是这一片文章实现了one-stage的方法，其中的很多tricks是值得注意的，但是这篇文章仍然是anchor-based的，所以后续有往anchor-free 方向靠拢的可能性。 ","link":"https://tonywangziteng.github.io/post/pbrnet/"}]}